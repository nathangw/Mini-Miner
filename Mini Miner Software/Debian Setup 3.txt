

********************  COMMON COMMANDS  ********************

Clear the watchdog log:   sudo truncate -s 0 /var/log/miner-watchdog.log

View the watchdog log:   sudo tail -n 50 /var/log/miner-watchdog.log

View the watchdog log live:    sudo tail -f /var/log/miner-watchdog.log

Watchdog Status:   sudo systemctl status miner-watchdog   















********************  TEST LED   ********************


Verify LED is connected:    ls -l /dev/ttyACM* /dev/ttyUSB* 2>/dev/null
    Must how crw, 166 and ttyACM0 as below.
crw-rw---- 1 root dialout 166, 0 Nov 26 21:20  /dev/ttyACM0

Erase corrupted port config:   sudo rm /dev/ttyACM0

INIT THE LED:   sudo stty -F /dev/ttyACM0 9600 raw -echo -echoe -echok -echoctl -echoke

SET RED:   echo "#FF0000" | sudo tee /dev/ttyACM0 >/dev/null

SET GREEN:   echo "#00FF00" | sudo tee /dev/ttyACM0 >/dev/null














********************  SYSTEM STABILITY LOG   ********************

This is required to be installed so the 5 minute startup email can show any system stability issues.

Command:   sudo apt install rasdaemon
Command:   sudo systemctl enable --now rasdaemon

Check the log:   sudo ras-mc-ctl --errors












The miner watchdog is a continuous monitoring script that checks the miner’s hashrate, CPU temperature, and power every few seconds using the local miner-status server, compares those values against thresholds loaded from /etc/miner.env, and tracks how long any abnormal condition persists. If the miner becomes too cold, too hot, or maintains a low hashrate for either short-term or long-term periods—and enough time has passed since the last reboot—it performs a safe automatic reboot after emailing a detailed report containing current metrics and recent log excerpts. It also manages a USB status LED, pulsing green when healthy, red when warm, and turning off during error states or just before reboot. The watchdog ensures only one copy runs, logs all key events, sends a startup status email after five minutes, and ultimately acts as a full health-protection and recovery system to keep the miner running reliably and autonomously.







********************  MINER WATCHDOG   ********************


Command:   sudo nano /usr/local/bin/miner-watchdog.sh
#########################################################
#!/bin/bash
# miner-watchdog.sh — Monitors miner via miner-status server and enforces auto-reboot rules
# (c) 2026 Nathan Gwozdecki
# Version
# 1.7 - added diagnostic network info to all emails.
# 1.8 - added more network diagnostics to all emails.
# 1.9 - organized functions better
# 2.0 - fixed email subject bug
# 2.1 - added daily DNS internet check 
# 2.2 - cleaned LED code, removed bc dependenacy, added dependency checks, internet check every hour
# 2.3 - added 10 second delay before sending email

set -Eeuo pipefail      		       # note the extra -E so ERR fires in functions/$(...)
[ -f /etc/miner.env ] && . /etc/miner.env      # load shared configuration (STATUS_PORT, STATUS_TOKEN, XMRIG vars, etc.)

#set -x   #(REMOVE)  Use this for debugging crashes by logging all commands
         #Command to clear the log:   sudo truncate -s 0 /var/log/miner-watchdog.log
         #Command to search the log:   tac /var/log/miner-watchdog.log | grep -i -m 1 -C 5 "line" | tac

# ---- single-instance lock ----
exec {LOCKFD}<>/run/miner-watchdog.lock || exit 0
flock -n "$LOCKFD" || exit 0

LOG="/var/log/miner-watchdog.log"
PASSWORD="${STATUS_TOKEN}"    # use shared STATUS_TOKEN from /etc/miner.env for local miner authentication

MINER_HOST="127.0.0.1"
MINER_PORT="${STATUS_PORT}"   # use STATUS_PORT from /etc/miner.env for the local miner-status TCP listener
LOOP_INTERVAL=10   #DO NOT SET LESS THAN 6 SECONDS

# --- Default Thresholds if not found in miner.env  ---
CPU_LOW="${CPU_LOW:-30}"
CPU_HIGH="${CPU_HIGH:-80}"
CPU_WARN="${CPU_WARN:-70}"
HASH_LOW_5M="${HASH_LOW_5M:-8000}"
HASH_LOW_30M="${HASH_LOW_30M:-10000}"
LED_BRT="${LED_BRT:-50}"

printf '%s Using thresholds: CPU_LOW=%s CPU_WARN=%s CPU_HIGH=%s HASH_LOW_5M=%s HASH_LOW_30M=%s\n' \
  "$(date '+%F %T')" "$CPU_LOW" "$CPU_WARN" "$CPU_HIGH" "$HASH_LOW_5M" "$HASH_LOW_30M" >>"$LOG"

COOL_LIMIT_MIN=5
LOWHASH5_LIMIT_MIN=5
LOWHASH30_LIMIT_MIN=30
CPU_HIGH_MIN=5

# --- Convert minutes to seconds ---
COOL_LIMIT_SEC=$((COOL_LIMIT_MIN*60))
LOWHASH5_LIMIT_SEC=$((LOWHASH5_LIMIT_MIN*60))
LOWHASH30_LIMIT_SEC=$((LOWHASH30_LIMIT_MIN*60))
CPU_HIGH_LIMIT_SEC=$((CPU_HIGH_MIN*60))
REBOOT_GUARD_SEC=3600   #1 hour

# --- Counters/State ---
CoolSecs=0
LowHash5Secs=0
LowHash30Secs=0
CPUHighSec=0
reboot_defer=0
StartupEPOCH=$(date +%s) 
Last1hrEPOCH=$StartupEPOCH 
StartupEmailSent=0
DNSGood=1             # pings google every hour to show internet is working
LastLoop24hr=""
LEDStatus=""          # Shows LED status to other scripts by writing to a file
LED_TTY_PATH=""       # Port Location of the LED

# For change detection
LastHR=0
LastTC=0
LastWT=0
LastCoolSecs=0
LastLow5Secs=0
LastLow30Secs=0
LastCPUHighSec=0
LastLoggedHour=""

HOSTNAME_STR="$(hostname)"
EMAIL_LIB="/usr/local/bin/send_email.sh"

# --- Import email function ---
if [ -r "$EMAIL_LIB" ]; then
  source "$EMAIL_LIB"
else
  send_email() { echo "[WARN] send_email.sh missing — $1: $2" >>"$LOG"; }
fi

ts() { date '+%Y-%m-%d %H:%M:%S'; }
log() { printf '%s %s\n' "$(ts)" "$*" >>"$LOG"; }

# Capture all stderr from the script into the log
exec 2>>"$LOG"



check_dependencies() {
  log "Checking required system dependencies..."

  local missing_required=0 cmd
  local required_cmds=(bash date ip ss jq nc timeout awk sed grep journalctl systemctl hostname curl traceroute ras-mc-ctl timedatectl dmesg getent udevadm stty)

  for cmd in "${required_cmds[@]}"; do
    command -v "$cmd" >/dev/null 2>&1 || { log "ERROR: Required dependency missing: $cmd"; missing_required=1; }
  done

  if (( missing_required == 0 )); then
    log "Dependency check passed: all required commands present"
  else
    log "ERROR: One or more REQUIRED dependencies are missing — watchdog may not function correctly"
  fi
}





# --- Reboot email diagnostics (network/session snapshots) ---
diag_block() {
  local label="$1"; shift
  local output
  output=$("$@" 2>&1 || true)

  {
    printf '\n\n========== %s ==========\n\n' "$label"
    if [ -n "$output" ]; then
      echo "$output" | sed 's/^/   /'
      printf '\n'
    else
      printf '   (no output)\n\n'
    fi
    printf '\n'
  }
}


# Simple, busybox-friendly traceroute formatter (updated)
format_traceroute() {
  local title="$1"
  local raw_output="$2"
  local has_hops=0

  printf '\n\n========== %s ==========\n\n' "$title"

  # Print the header, indented
  echo "$raw_output" | head -n1 | sed 's/^/ /'

  # Process hop lines using process substitution to avoid subshell
  while IFS= read -r line; do
    # Trim whitespace
    line=$(printf '%s' "$line" | sed 's/^[ \t]*//; s/[ \t]*$//')
    
    # Skip empty lines and full "* * *" lines
    [[ -z "$line" ]] && continue
    [[ "$line" == "* * *" ]] && continue
    
    # Only process lines that start with a number (hop lines)
    if [[ "$line" =~ ^[0-9] ]]; then
      printf ' %s hop: %s\n' "$((++has_hops))" "$line"
    fi
  done < <(echo "$raw_output" | tail -n+2)

  if [ "$has_hops" -eq 0 ]; then
    printf '  (No intermediate routers responded to probes – this is very common on the internet and usually means nothing is wrong)\n'
  fi
}

collect_reboot_diags() {
  local out=""
  local router_ip="${DIAG_ROUTER_IP:-192.168.1.1}"
  local wan_ip="${DIAG_WAN_IP:-1.1.1.1}"
  local wan_name="Cloudflare DNS (1.1.1.1)"

  out+="When: $(ts)"$'\n'
  out+="Device: $HOSTNAME_STR"$'\n'
  out+=$'\n'
  out+="IMPORTANT NOTES:"$'\n'
  out+=" • This report shows the network state exactly when the email was sent – it's a snapshot, not a full history."$'\n'
  out+=" • The ping tests only check if we can reach your router and one public internet address. They do NOT test the mining pools directly."$'\n'
  out+=" • DNS checks below only show if pool names can be turned into IP addresses – no actual mining traffic is sent."$'\n'
  out+=" • Active connection lists only show connections that are open right now. Empty lists are completely normal if the miner is idle or using a different pool."$'\n'
  out+=$'\n'

  out+="--- QUICK NETWORK SUMMARY (at the moment this report was created) ---\n\n"

  local def_route def_if src_ip
  def_route="$(ip route show default 2>/dev/null | head -n1 || true)"
  def_if="$(awk '/default/ {for(i=1;i<=NF;i++) if($i=="dev"){print $(i+1); exit}}' <<<"$def_route" 2>/dev/null || true)"
  src_ip="$(ip -4 -br addr show "${def_if:-}" 2>/dev/null | awk '{print $3}' | cut -d/ -f1 | head -n1 || true)"

  local ping_router_ok="FAIL" ping_wan_ok="FAIL"
  ping -c 1 -W 1 "$router_ip" >/dev/null 2>&1 && ping_router_ok="OK"
  ping -c 1 -W 1 "$wan_ip" >/dev/null 2>&1 && ping_wan_ok="OK"

  out+="How internet traffic leaves this device : ${def_route:-'(no internet route found)'}"$'\n'
  out+="Main network interface                 : ${def_if:-'(unknown)'}"$'\n'
  out+="Device's own IP address                : ${src_ip:-'(none detected)'}"$'\n'
  out+="Can reach router (local network)       : ${ping_router_ok} (${router_ip})"$'\n'
  out+="Can reach internet                     : ${ping_wan_ok} (${wan_name})"$'\n'
  out+=$'\n'

  out+=$(diag_block "Full routing table – shows exactly how this device sends traffic out" \
    bash -lc 'ip route')

  out+=$'\n'$(diag_block "Network interfaces status – 'UP' means cable connected / Wi-Fi associated" \
    bash -lc 'ip -br link')

  out+=$'\n'$(diag_block "All IP addresses assigned to this device" \
    bash -lc 'ip -br addr')

  out+=$'\n'$(diag_block "Reachability test to router – sending 5 pings to your gateway (${router_ip})" \
    bash -lc "ping -c 5 -W 1 $router_ip")

  out+=$'\n'$(diag_block "Internet reachability test – sending 5 pings to ${wan_name}" \
    bash -lc "ping -c 5 -W 1 $wan_ip")

  # Traceroute to internet
  local tr_internet="$(traceroute -n -w 2 -q 2 $wan_ip 2>/dev/null || echo 'traceroute failed or not available')"
  out+=$'\n'$(format_traceroute "Path to internet (traceroute to Cloudflare DNS) – helps spot slow or blocked hops" "$tr_internet")

  out+=$'\n'






  if [ -n "${DIAG_POOLS:+x}" ]; then  #check if using a local xmrig proxy


    # Traceroute to each pool
    local p host tr_pool
    for p in $DIAG_POOLS; do
      host="${p%%:*}"
      port="${p##*:}"

      # Run traceroute ONCE, capture all output; don't leak to top of email
      if tr_pool="$(traceroute -n -w 2 -q 2 "$host" 2>&1)"; then
        :
      else
        tr_pool="traceroute failed (host: $host)"
      fi

      out+="$(format_traceroute "Path to mining pool ($host) – checks route to pool server" "$tr_pool")"
      out+=$'\n'
    done


    out+=$(diag_block "DNS servers this device is using – wrong ones can prevent pool names from resolving" \
      bash -lc 'cat /etc/resolv.conf || systemd-resolve --status 2>/dev/null || true')

    out+=$'\n\n\n========== Port reachability to each mining pool (secure mining port – Open = good) ==========\n'
    for p in $DIAG_POOLS; do
      host="${p%%:*}"
      port="${p##*:}"
      out+=$'\n'"Pool hostname: $host:$port"
      timeout 5 bash -c "echo > /dev/tcp/$host/$port" >/dev/null 2>&1 \
        && out+="   :   Open (connection succeeded)"$'\n' \
        || out+="   :   Blocked or timeout"$'\n'
    done



    # Extra detail to help distinguish DNS issues, IPv6 issues, and TLS/443 blocking
    out+=$'\n\n========== Extra connectivity details for each mining pool (DNS + TLS probe) ==========\n'
    for p in $DIAG_POOLS; do
      host="${p%%:*}"
      port="${p##*:}"

      out+=$'\n'"Pool hostname: $host:$port"$'\n'

      # --- DNS resolution details (both IPv4 and IPv6 if present) ---
      local ahosts
      ahosts="$(getent ahosts "$host" 2>/dev/null || true)"
      if [ -n "$ahosts" ]; then
        out+="Resolved addresses via getent ahosts:"$'\n'
        out+="$ahosts"$'\n'
      else
        out+="Resolved addresses via getent ahosts: (none – DNS lookup failed)"$'\n'
      fi

      # --- Simple IPv4-only extraction (helps catch “IPv6 works, IPv4 blocked” cases) ---
      local ipv4_list
      ipv4_list="$(printf '%s\n' "$ahosts" | awk '/^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/ {print $1}' || true)"
      if [ -n "$ipv4_list" ]; then
        out+="IPv4 addresses used for testing:"$'\n'
        out+="$ipv4_list"$'\n'
      else
        out+="IPv4 addresses used for testing: (none – hostname may be IPv6-only)"$'\n'
      fi

      # --- TLS / HTTPS probe with curl (only if curl is installed) ---
      if command -v curl >/dev/null 2>&1; then
        local curl_out
        # We only keep the first ~12 lines so the email doesn't explode
        curl_out="$(
          curl -v --connect-timeout 5 --max-time 5 "https://$host:$port" </dev/null 2>&1 \
            | sed -n '1,12p' \
            || true
        )"
        if [ -n "$curl_out" ]; then
          out+="curl -v TLS probe (first lines):"$'\n'"$curl_out"$'\n'
        else
          out+="curl -v TLS probe: (no output – likely hard timeout)"$'\n'
        fi
      else
        out+="curl not installed – skipping TLS probe on $host:$port"$'\n'
      fi
    done


    # Extra per-IP port test so we can see which Hashvault backend is failing
    out+=$'\n\n========== Per-IP port reachability for each mining pool (helps debug Hashvault) ==========\n'
    for p in $DIAG_POOLS; do
      host="${p%%:*}"
      port="${p##*:}"

      out+=$'\n'"Pool hostname: $host:$port"$'\n'

      # Get unique IPv4 addresses for this host
      local ahosts ipv4_list ip any_ok
      ahosts="$(getent ahosts "$host" 2>/dev/null || true)"
      ipv4_list="$(printf '%s\n' "$ahosts" \
                    | awk '/^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/ {print $1}' \
                    | sort -u)"

      if [ -z "$ipv4_list" ]; then
        out+="   (No IPv4 addresses found – DNS failure or IPv6-only host)\n"
        continue
      fi

      any_ok=0
      for ip in $ipv4_list; do
        if timeout 5 bash -lc "echo > /dev/tcp/$ip/$port" >/dev/null 2>&1; then
          out+="   [$ip] : Open (TCP handshake succeeded)\n"
          any_ok=1
        else
          out+="   [$ip] : Blocked or timeout\n"
        fi
      done

      if (( any_ok == 1 )); then
        out+="   Overall: at least one backend reachable\n"
      else
        out+="   Overall: ALL backends failed – this really looks blocked\n"
      fi
    done










    out+=$'\n\n========== ICMP ping reachability to each mining pool (5 packets) – checks basic IP-level reachability ==========\n\n'
    out+="Note: Many mining pools block or ignore pings – FAIL here is often normal and does NOT mean mining won't work.\n"
    firstline=true
    for p in $DIAG_POOLS; do
      host="${p%%:*}"
      port="${p##*:}"
      out+="\n\nPool hostname: $host:$port"
      out+=$'\n'
      if "$firstline"; then
        firstline=false
        out+=$'\n'
      fi
      # getent may fail; don't let that kill the loop
      local ip="$(getent ahosts "$host" 2>/dev/null | awk '/^[0-9.]/{print $1; exit}' || true)"
      if [ -n "$ip" ]; then
        local ping_result="$(ping -c 5 -W 1 "$ip" 2>&1 || true)"
        out+="$ping_result"$'\n'
        if grep -q "100% packet loss" <<<"$ping_result"; then
          out+="Result: FAIL (100% loss)"$'\n'
        else
          local loss="$(grep "packet loss" <<<"$ping_result" | awk '{print $(NF-4)}' | tr -d '%')"
          local avg="$(grep "rtt min/avg/max" <<<"$ping_result" | awk -F'/' '{print $5}')"
          out+="Result: OK (${loss}% loss, avg RTT ${avg:-unknown} ms)"$'\n'
        fi
      else
        out+="Could not resolve to IPv4 address – skipping ping."$'\n'
      fi
    done


    out+=$(diag_block "Currently active secure (TLS) connections to port 443 – mining pools usually use this" \
      bash -lc "ss -tnip '( dport = :443 )' | tail -n +2 | sed 's/^/ /'" || true)

    if [ -n "${DIAG_POOLS:-}" ]; then
      out+=$'\n\n'
      out+=$'\n========== Raw ss output for each mining pool (advanced detail) =========\n\n'
      for p in $DIAG_POOLS; do
        host="${p%%:*}"
        port="${p##*:}"
        out+="Pool hostname: $host:$port\n"
        local ip="$(getent ahosts "$host" 2>&1 | awk 'NR==1{print $1}' || true)"
        if [ -n "$ip" ]; then
          out+="Resolved IP: $ip\n\n"
          local conn="$(ss -tnpi "dst $ip:$port" 2>&1 || true)"
          if [[ -n "$conn" && "$conn" != *"No such file"* ]]; then
            out+="$conn\n\n"                  # ss output with its own header + blank line after
          else
            out+="No active connections right now.\n\n"
          fi
        else
          out+="Could not resolve hostname.\n\n"
        fi
      done
    fi

  fi    #check if using a local xmrig proxy




  out+=$(diag_block "MTU test to internet – fragmentation issues can cause mining dropouts" \
    bash -lc "ping -c 1 -M do -s 1472 $wan_ip || true")

  out+=$'\n'$(diag_block "System clock and time synchronization – clock jumps can break TLS connections" \
    bash -lc 'timedatectl')

  out+=$'\n'$(diag_block "Recent kernel messages (last 40 lines) – for Wi-Fi drops, cable issues, etc." \
    bash -lc 'dmesg | tail -n 40')

  printf '%s\n' "$out"
}






uptime_text() {
  local uptime_str="Unknown"

  if ! systemctl is-active --quiet xmrig 2>/dev/null; then
    printf '%s' "$uptime_str"
    return 0
  fi

  local start_time start_sec now_sec seconds

  start_time="$(systemctl show xmrig --property=ActiveEnterTimestamp --value 2>/dev/null || true)"
  [[ -z "$start_time" ]] && { printf '%s' "$uptime_str"; return 0; }

  now_sec="$(date +%s)"
  start_sec="$(date -d "$start_time" +%s 2>/dev/null || echo "")"

  # Fallback if date parsing failed or is not numeric
  [[ "$start_sec" =~ ^[0-9]+$ ]] || start_sec="$now_sec"

  seconds=$(( now_sec - start_sec ))
  (( seconds < 0 )) && seconds=0

  if (( seconds >= 86400 )); then
    local whole_days=$(( seconds / 86400 ))
    local remainder=$(( seconds % 86400 ))
    local fraction=$(( (remainder * 10) / 86400 ))   # 0–9
    uptime_str=$(printf "%d.%d Days" "$whole_days" "$fraction")

  elif (( seconds >= 3600 )); then
    local whole_hours=$(( seconds / 3600 ))
    local remainder=$(( seconds % 3600 ))
    local fraction=$(( (remainder * 10) / 3600 ))
    uptime_str=$(printf "%d.%d Hours" "$whole_hours" "$fraction")

  else
    local mins=$(( seconds / 60 ))
    uptime_str="${mins} Minutes"
  fi

  printf '%s' "$uptime_str"
}




send_status_email() {
  local subject="$1"

  # Refresh metrics right before emailing/rebooting
  get_metrics || true

  # SAFE: XMRig log — start at the *last* "Started xmrig" line,
  # then take the last 200 lines of that block.
  XMRIG_LOG=$(
    journalctl -u xmrig -n 1000 --no-pager -o cat 2>/dev/null \
      | awk '
          /Started xmrig/ {buf=""}      # reset buffer on each start
          {buf = buf $0 ORS}            # keep appending lines
          END {printf "%s", buf}        # print only lines after last start
        ' 2>/dev/null \
      | tail -200 2>/dev/null || true
  )
  XMRIG_LOG=$(echo "$XMRIG_LOG" | sed -r "s/\x1B\[[0-9;]*[A-Za-z]//g")


  # Fallback if nothing was captured above
  if [ -z "$XMRIG_LOG" ]; then
    XMRIG_LOG=$(
      journalctl -u xmrig -n 200 --no-pager -o cat 2>/dev/null \
        || echo "(No XMRig log data found)"
    )
    XMRIG_LOG=$(echo "$XMRIG_LOG" | sed -r "s/\x1B\[[0-9;]*[A-Za-z]//g")
  fi

  # SAFE: last 100 lines of ras-mc-ctl --errors (ignore failures)
  MCE_LOG_TAIL=$(
    ras-mc-ctl --errors 2>/dev/null \
      | tail -n 100 2>/dev/null || true
  )
  if [ -z "${MCE_LOG_TAIL:-}" ]; then
    MCE_LOG_TAIL="(No output from 'ras-mc-ctl --errors' or rasdaemon not active.)"
  fi

  WATCHDOG_TAIL=$(
    tail -n 100 "$LOG" 2>/dev/null \
      || echo "(No miner-watchdog.log data found at $LOG)"
  )


  # Network/session diagnostics (snapshot)
  REBOOT_DIAGS="$(collect_reboot_diags 2>&1 || echo "(collect_reboot_diags failed)")"

  sleep 10   # wait for network traffic to clear before sending email

  # SAFE: email failure is non-fatal
  send_email "$subject" "\
Host: $HOSTNAME_STR
Started: $(ts)
Hashrate: $HR H/s
CPU Temp: $TC C
Power: $WT W
Uptime: $(uptime_text)
Watchdog active.


==============================
     NETWORK DIAGNOSTICS
==============================
${REBOOT_DIAGS}


==========================================
 Last 100 lines of ras-mc-ctl --errors
==========================================
$MCE_LOG_TAIL


======================================
 Last 100 lines of miner-watchdog.log
======================================
$WATCHDOG_TAIL


==============================
 Last 200 lines of xmrig.log
==============================
$XMRIG_LOG
" || log "WARN: 5-min send_email failed (non-fatal)"
}






exit_trap() {
  local st=$?
  local hr=${HR:-N/A}
  local tc=${TC:-N/A}
  local wt=${WT:-N/A}
  log "WATCHDOG EXITED: status=$st (signal or error), last HR=$hr Temp=$tc Watts=$wt \
cool=${CoolSecs:-0}s hot=${CPUHighSec:-0}s low5=${LowHash5Secs:-0}s low30=${LowHash30Secs:-0}s"
}

err_trap() {
  local st=$?
  local line=${BASH_LINENO[0]:-0}
  local cmd=${BASH_COMMAND:-unknown}
  log "WATCHDOG ERROR: status=$st at line $line: $cmd (pid=$$, ppid=$PPID)"
  exit "$st"    # re-exit with the same status so EXIT trap sees the error
}

trap exit_trap EXIT
trap err_trap ERR

# Return epoch of the most recent "REBOOT triggered" in $LOG, or 0 if none
last_reboot_epoch() {
  local ts
  ts=$(tac "$LOG" 2>/dev/null | grep -m1 'REBOOT triggered:' | awk '{print $1" "$2}' 2>/dev/null || echo "")
  if [ -n "$ts" ] && date -d "$ts" >/dev/null 2>&1; then
    date -d "$ts" +%s
  else
    echo 0
  fi
}

# --- Miner query ---
get_metrics() {
  local json
  json=$(timeout 6 printf '%s\r\n' "$PASSWORD" | nc -w 4 "$MINER_HOST" "$MINER_PORT" 2>>"$LOG" || true)

  if [[ -z "$json" || "$json" == *"error"* ]]; then
    HR=0; TC=0; WT=0
    return 1
  fi
  HR=$(echo "$json" | jq -r '.hashrate // 0' 2>/dev/null || echo 0)
  TC=$(echo "$json" | jq -r '.temp // 0'     2>/dev/null || echo 0)
  WT=$(echo "$json" | jq -r '.watts // 0'    2>/dev/null || echo 0)

  # Ensure valid integers
  [[ "$HR" =~ ^[0-9]+$ ]] || HR=0
  [[ "$TC" =~ ^[0-9]+$ ]] || TC=0
  [[ "$WT" =~ ^[0-9]+$ ]] || WT=0
}

# --- Safe reboot ---
do_reboot() {
  local reason="$1"
  log "REBOOT triggered: $reason"
  internet_check
  send_status_email "$HOSTNAME_STR Miner Reboot $reason"
  set_led 0 0 0 || true  #turn off led
  sleep 10
  /sbin/reboot
}



init_led() {
  local d vid pid

  # search for our fit-statUSB (VID:PID 2047:03df) on ttyACM*
  for d in /dev/ttyACM*; do
    [[ -e "$d" ]] || continue
    [[ $(stat -c '%F' "$d" 2>/dev/null) == "character special file" ]] || continue

    vid=$(udevadm info -q property -n "$d" 2>/dev/null | awk -F= '/ID_VENDOR_ID=/ {print $2}')
    pid=$(udevadm info -q property -n "$d" 2>/dev/null | awk -F= '/ID_MODEL_ID=/ {print $2}')

    if [[ "$vid" == "2047" && "$pid" == "03df" ]]; then
      LED_TTY_PATH="$d"
      # configure serial ONCE
      stty -F "$LED_TTY_PATH" 9600 raw -echo -echoe -echok -echoctl -echoke 2>/dev/null || :
      return 0
    fi
  done

  LED_TTY_PATH=""
  return 1
}

set_led() {
  local r="$1" g="$2" b="$3"
  local dev="$LED_TTY_PATH"

  # no configured LED device
  [[ -n "$dev" && -e "$dev" ]] || return 1
  [[ $(stat -c '%F' "$dev" 2>/dev/null) == "character special file" ]] || return 1

  # validate 0–255
  local v
  for v in "$r" "$g" "$b"; do
    [[ "$v" =~ ^[0-9]+$ ]] && (( v >= 0 && v <= 255 )) || return 1
  done

  # convert to hex
  local rh gh bh
  printf -v rh '%02X' "$r"
  printf -v gh '%02X' "$g"
  printf -v bh '%02X' "$b"

  # write safely (no fake node creation)
  echo -e "#${rh}${gh}${bh}\n" | tee "$dev" >/dev/null 2>&1 || return 1

  return 0
}


save_LED() {
  local new_status="$1"   # the status passed to the function: "off", "red", or "green"

  if [[ "$new_status" != "$LEDStatus" ]]; then   # If the new status is different from the last saved one, write it to file
    printf '%s\n' "$new_status" > /var/run/led_status 2>/dev/null || true
    log "LED status changed to: $new_status"
  fi
  LEDStatus="$new_status"
}


internet_check() {
  if curl -s -f --connect-timeout 5 https://www.google.com/ >/dev/null 2>&1; then
    DNSGood=1
    log "Internet check to www.google.com Passed"
  else
    DNSGood=0
    log "ERROR: Internet is not working. Check DNS configuration."
  fi
}

loop24hr() {
  local now_date=$(date '+%Y-%m-%d')
  local now_time=$(date '+%H:%M')
  [[ "$now_date" == "$LastLoop24hr" || "$now_time" > "00:09" ]] && return 0
  LastLoop24hr="$now_date"
  log "loop24hr running..."

  # ===== Midnight code goes here =====

  internet_check   

}




check_dependencies   # show any missing dependencies in the log

# --- Initialize ---
init_led || log "LED init failed (fit-statUSB not found)"

set_led 0 0 0 || true  #turn off led
log "Starting miner watchdog..."

# --- Main loop ---
while true; do
  get_metrics || true

  now=$(date +%s)

  last_reboot_ts=$(last_reboot_epoch)
  if (( last_reboot_ts > 0 && now - last_reboot_ts < REBOOT_GUARD_SEC )); then
    reboot_defer=1
  else
    reboot_defer=0
  fi

  # ===== Counters =====
  (( TC < CPU_LOW )) && ((CoolSecs+=LOOP_INTERVAL)) || CoolSecs=0
  (( TC > CPU_HIGH )) && ((CPUHighSec+=LOOP_INTERVAL)) || CPUHighSec=0
  (( HR < HASH_LOW_5M )) && ((LowHash5Secs+=LOOP_INTERVAL)) || LowHash5Secs=0
  (( HR < HASH_LOW_30M )) && ((LowHash30Secs+=LOOP_INTERVAL)) || LowHash30Secs=0

  # ===== Reboot triggers =====
  if (( reboot_defer == 0 )); then
    if (( CoolSecs >= COOL_LIMIT_SEC )); then
      set_led 0 0 0 || true  #turn off led
      do_reboot "CPU below ${CPU_LOW}C for ${COOL_LIMIT_MIN} min"
    elif (( CPUHighSec >= CPU_HIGH_LIMIT_SEC )); then
      set_led 0 0 0 || true  #turn off led
      do_reboot "CPU above ${CPU_HIGH}C for ${CPU_HIGH_MIN} min"
    elif (( LowHash5Secs >= LOWHASH5_LIMIT_SEC )); then
      set_led 0 0 0 || true  #turn off led
      do_reboot "Hashrate below ${HASH_LOW_5M} H/s for ${LOWHASH5_LIMIT_MIN} min"
    elif (( LowHash30Secs >= LOWHASH30_LIMIT_SEC )); then
      set_led 0 0 0 || true  #turn off led
      do_reboot "Hashrate below ${HASH_LOW_30M} H/s for ${LOWHASH30_LIMIT_MIN} min"
    fi
  fi


  # ===== Logging (changes or top of hour) =====
  current_hour=$(date +%H)
  log_needed=false
  diff_hr=$(( HR>LastHR ? HR-LastHR : LastHR-HR ))
  diff_wt=$(( WT>LastWT ? WT-LastWT : LastWT-WT ))
  diff_tc=$(( TC>LastTC ? TC-LastTC : LastTC-TC ))

  if (( LastHR == 0 || (diff_hr * 100 / (LastHR + 1)) >= 10 )); then log_needed=true; fi
  if (( LastWT == 0 || (diff_wt * 100 / (LastWT + 1)) >= 10 )); then log_needed=true; fi
  if (( LastTC == 0 || diff_tc >= 3 )); then log_needed=true; fi

  # Log only if any counter increased by 60+ seconds since last log
  if (( CoolSecs - LastCoolSecs >= 60 || LowHash5Secs - LastLow5Secs >= 60 || LowHash30Secs - LastLow30Secs >= 60 || CPUHighSec - LastCPUHighSec >= 60 )); then
    log_needed=true
  fi

  if [[ "$current_hour" != "$LastLoggedHour" ]]; then
    log_needed=true; LastLoggedHour="$current_hour"
  fi

  if $log_needed; then
    log "HR=$HR Temp=${TC}°C Watts=${WT} | cool=${CoolSecs}s, hot=${CPUHighSec}s, low5=${LowHash5Secs}s, low30=${LowHash30Secs}s"
    LastHR=$HR; LastTC=$TC; LastWT=$WT
    LastCoolSecs=$CoolSecs; LastLow5Secs=$LowHash5Secs; LastLow30Secs=$LowHash30Secs; LastCPUHighSec=$CPUHighSec
  fi

  # ================= Send 5 minute email =================
  if (( StartupEmailSent == 0 )); then
    if (( $(date +%s) - StartupEPOCH >= 300 )); then  
      internet_check
      send_status_email "$HOSTNAME_STR XMRig Running (5 min)"
      StartupEmailSent=1
    fi
  fi
  
  # ================= Run once per Hour =================
  if (( now - Last1hrEPOCH >= 3600 )); then   
    Last1hrEPOCH=$now
    internet_check
  fi

  loop24hr # runs at midnight to handle maintenace functions

  # ==== Perfectly synchronized LED pulse to 10 second intervals ====
  now_sec=$(date +%s)
  now_ns=$(date +%N 2>/dev/null || echo "000000000")  # fallback if %N unsupported
  now_frac="${now_ns:0:3}"                            # first 3 digits = milliseconds
  epoch_ms=$(( now_sec * 1000 + 10#$now_frac ))

  # Which 10-second block are we in? (0 or 1)
  block=$(( (epoch_ms / (LOOP_INTERVAL * 1000)) % 2 ))

  # Brightness for current block 
  if (( block == 0 )); then
    PULSE_VAL=$(( LED_BRT ))        
  else
    PULSE_VAL=$(( LED_BRT * 2 ))
    (( PULSE_VAL > 255 )) && PULSE_VAL=255
  fi

  # ==== Sleep exactly to next 10-second boundary (with 150 ms guard) ====
  remaining_ms=$(( (LOOP_INTERVAL * 1000) - (epoch_ms % (LOOP_INTERVAL * 1000)) ))
  if (( remaining_ms < 150 )); then
    remaining_ms=$(( remaining_ms + LOOP_INTERVAL * 1000 ))
  fi
  sleep_sec=$(( remaining_ms / 1000 ))
  sleep_ms=$(( remaining_ms % 1000 ))

  sleep "${sleep_sec}.${sleep_ms}" 2>/dev/null || sleep "$sleep_sec"  # works on any modern sleep

  # ===== LED control (silent, synchronized across miners) =====
  if (( TC > CPU_HIGH || CoolSecs > 0 || LowHash5Secs > 0 || LowHash30Secs > 0 || CPUHighSec > 0 || DNSGood == 0 )); then
    set_led 0 0 0 || true                      # turn off led (error/trigger states)
    save_LED "off"
  elif (( TC > CPU_WARN )); then
    set_led "$PULSE_VAL" 0 0 || true           # red pulsing when warm
    save_LED "red"
  else
    set_led 0 "$PULSE_VAL" 0 || true           # green pulsing when healthy
    save_LED "green"
  fi

done
#########################################################
Ctrl-O, Enter, Ctrl-X



Command:   sudo chmod +x /usr/local/bin/miner-watchdog.sh


Run Manually to Test:    sudo bash -x /usr/local/bin/miner-watchdog.sh
Stop the Test: Ctrl-C





Command:   sudo nano /etc/systemd/system/miner-watchdog.service
#########################################################
[Unit]
Description=Miner Watchdog (auto-reboot monitor)
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=root
ExecStart=/usr/local/bin/miner-watchdog.sh
Restart=always
RestartSec=10
StandardOutput=append:/var/log/miner-watchdog.log
StandardError=append:/var/log/miner-watchdog.log

[Install]
WantedBy=multi-user.target
#########################################################
Ctrl-O, Enter, Ctrl-X



Command:   sudo systemctl daemon-reload
Command:   sudo systemctl enable miner-watchdog.service
Command:   sudo systemctl start miner-watchdog.service


Command:   sudo reboot  (you can reboot later)










